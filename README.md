# Evaluierung von RAG-Ergebnissen

## üîç Projekt√ºbersicht

Dieses Projekt befasst sich mit der Evaluierung von Retrieval-Augmented Generation (RAG) mithilfe verschiedener Evaluierungsmetriken. Dabei kommt insbesondere die Python-Bibliothek [TruLens](https://www.trulens.org) zum Einsatz. Die Evaluierung basiert auf Musikdaten, wobei Nutzer entweder einen vorhandenen Datensatz verwenden oder ihre eigenen Song-Eigenschaften testen k√∂nnen.

---

## üìÇ Ordnerstruktur

Im Root-Verzeichnis befinden sich mehrere zentrale Bereiche: **data** enth√§lt die Rohdaten `raw/`, vorverarbeitete Datens√§tze `preprocessed/` und Ergebnisse `results/`. **evaluation** umfasst Module zur Bewertung, wie √Ñhnlichkeitsmetriken (`similarity/`) und Trulens-Tools (`trulens/`). **setup** bietet Skripte zur Umgebungseinrichtung, w√§hrend **utils** Hilfsfunktionen wie Datenbankverbindungen und Formatierungswerkzeuge bereitstellt. Die Hauptlogik f√ºr RAG befindet sich in `rag.py`, und alles ist √ºber die Hauptdatei `run.py` verbunden.

Die Ordnerstruktur ist wie folgt aufgebaut:
```plaintext
.venv/                  
src/                    
‚îú‚îÄ‚îÄ data/               
‚îÇ   ‚îú‚îÄ‚îÄ raw/            
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.csv    
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dislike.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ good.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ no.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yes.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocessed/ 
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ covariance_matrix.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.csv
‚îÇ   ‚îú‚îÄ‚îÄ results/ 
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ overall_results.json     
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ meta_results.py
‚îú‚îÄ‚îÄ evaluation/         
‚îÇ   ‚îú‚îÄ‚îÄ similarity/     
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cosine.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ euclidean.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mahalanobis.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manhattan.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pearson.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ print_similarity.py
‚îÇ   ‚îú‚îÄ‚îÄ trulens/        
‚îÇ       ‚îú‚îÄ‚îÄ evaluation.py
‚îú‚îÄ‚îÄ setup/              
‚îÇ   ‚îú‚îÄ‚îÄ create_table.py
‚îÇ   ‚îú‚îÄ‚îÄ data_to_pgvector.py
‚îÇ   ‚îú‚îÄ‚îÄ pgvector_extension.py
‚îú‚îÄ‚îÄ utils/              
‚îÇ   ‚îú‚îÄ‚îÄ connect_db.py
‚îÇ   ‚îú‚îÄ‚îÄ formatting.py
‚îÇ   ‚îú‚îÄ‚îÄ retrieval.py
‚îú‚îÄ‚îÄ rag.py
.env                               
README.md               
requirements.txt        
run.py                          
```
---

## üéß Datengrundlage

Die Daten stammen aus dem [Spotify Recommendation Dataset](https://www.kaggle.com/datasets/bricevergnou/spotify-recommendation). Der Datensatz umfasst Informationen wie Danceability, Energy, Tempo und andere musikalische Merkmale.

### Zusammenfassung der Merkmale
- **Danceability**: Eignung eines Songs zum Tanzen.
- **Energy**: Wahrgenommene Intensit√§t und Aktivit√§t.
- **Key**: Musikalischer Schl√ºssel.
- **Loudness**: Lautst√§rke in Dezibel.
- **Mode**: Modus (Dur oder Moll).
- **Speechiness**: Anteil an gesprochenem Wort.
- **Instrumentalness**: Wahrscheinlichkeit, dass ein Song instrumental ist.
- **Valence**: Positivit√§t der musikalischen Stimmung.

Weitere Informationen zu den Attributen finden Sie in der [Spotify-API-Dokumentation](https://developer.spotify.com/documentation/web-api/).

---

## üìä Evaluierungsmetriken

### Retrieval-basierte Metriken
- **Cosine Similarity**: Misst die √Ñhnlichkeit zwischen zwei Vektoren.
- **Euclidean Distance**: Abstandsma√ü in einem n-dimensionalen Raum.
- **Manhattan Distance**: Absolute Distanz zwischen Vektorkoordinaten.
- **Mahalanobis Distance**: Skaliertes Abstandsma√ü.
- **Pearson Correlation**: Korrelation zwischen zwei Variablen.

### Generations-basierte Metriken
- **Correctness**: Korrektheit der generierten Antworten.
- **Groundedness**: Grad, zu dem generierte Antworten durch die Quelle gest√ºtzt werden.
- **Relevance**: Relevanz der Antwort (mit Begr√ºndungen).
- **Context Relevance**: Passgenauigkeit der Antwort im Kontext (mit Begr√ºndungen).

---

## üöÄ Erste Schritte

### Voraussetzungen
- **Pflicht**: `OPENAI_API_KEY`
- **Optional**: `GROQ_API_KEY` f√ºr zus√§tzliche Generierungsmodelle.

### Installation
1. **Virtuelle Umgebung aufsetzen**:
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   ```
2. **Abh√§ngigkeiten installieren**:
   ```bash
   pip install -r requirements.txt
   ```

3. **PostgreSQL und pgVector installieren** (f√ºr macOS):
    ```bash
    brew install postgresql@17
    brew install libpq
    echo 'export PATH="/opt/homebrew/opt/libpq/bin:$PATH"' >> ~/.zshrc
    echo 'export LDFLAGS="-L/opt/homebrew/opt/libpq/lib"' >> ~/.zshrc
    echo 'export CPPFLAGS="-I/opt/homebrew/opt/libpq/include"' >> ~/.zshrc
    echo 'export PKG_CONFIG_PATH="/opt/homebrew/opt/libpq/lib/pkgconfig"' >> ~/.zshrc

    source ~/.zshrc
    brew services start postgresql@17
    ```

---

## üîß Datenaufbereitung
Die Daten wurden bereits vorverarbeitet. Falls eine erneute Verarbeitung erforderlich ist:
```bash
python src/data_preprocessing.py
```

---

## üî¢ Setup

1. **.env-Datei einrichten**:
   ```
   DB_NAME=<name>
   DB_USER=<user>
   DB_PASSWORD=<your_password>
   DB_HOST=<your_host>
   DB_PORT=<your_port>
   OPENAI_API_KEY=<your_api_key>
   GROQ_API_KEY=<optional>
   ```

2. **Vektordatenbank vorbereiten**:
   ```bash
   python run.py setup
   ```

---

## üåê Nutzung

### Evaluierung vorhandener Daten

Evaluieren Sie RAG basierend auf einem vorhandenen Datensatz:
```bash
python run.py eval-data --data-size <Datengr√∂√üe> --similarity-search <Methode> --top-k <Anzahl> --model <Generierungsmodell> --eval-model <Evaluierungsmodell>
```
**Parameterbeschreibung**
- `--data-size <Datengr√∂√üe>`: Gibt an, welche Menge der Daten f√ºr die Evaluierung verwendet werden soll.
- `--similarity-search <Suchmetrik>`: W√§hlen Sie die Methode zur √Ñhnlichkeitssuche.
- `--top-k <Anzahl der Ergebnisse>`: Legt fest, wie viele Top-Ergebnisse aus der √Ñhnlichkeitssuche zur√ºckgegeben werden sollen.
- `--model <Generierungsmodell>`: Das Sprachmodell, das f√ºr die Generierung verwendet wird.
- `--eval-model <Evaluierungsmodell>`: Das Sprachmodell, das f√ºr die Evaluierung verwendet wird.

Beispiel:
```bash
python run.py eval-data --data-size 50 --similarity-search cosine --top-k 5 --model "gpt-3.5-turbo" --eval-model "gpt-3.5-turbo"
```

### Interaktive Tests

Erstellen Sie individuelle Anfragen und testen Sie RAG mit benutzerdefinierten Song-Eigenschaften:
```bash
python run.py eval-user --stage <Evaluierungsstufe> --similarity-search <Suchmetrik> --top-k <Anzahl der Ergebnisse> --model <Generierungsmodell> --eval-model <Evaluierungsmodell> --input "<Eigenschaftsvektor>"
```
**Parameterbeschreibung**
- `--stage <Evaluierungsstufe>`: Gibt die Evaluierungsstufe an.
- `--similarity-search <Suchmetrik>`: W√§hlen Sie die Methode zur √Ñhnlichkeitssuche.
- `--top-k <Anzahl der Ergebnisse>`: Legt fest, wie viele Top-Ergebnisse aus der √Ñhnlichkeitssuche zur√ºckgegeben werden sollen.
- `--model <Generierungsmodell>`: Das Sprachmodell, das f√ºr die Generierung verwendet wird.
- `--eval-model <Evaluierungsmodell>`: Das Sprachmodell, das f√ºr die Evaluierung verwendet wird.
- `--input "<Eigenschaftsvektor>"`: Ein benutzerdefinierter Vektor, der die Eigenschaften des zu bewertenden Songs repr√§sentiert. 


Beispiel:
```bash
python run.py eval-user --stage all --similarity-search cosine --top-k 5 --model "gpt-3.5-turbo" --eval-model "gpt-3.5-turbo" --input "[0.7585784313725491,0.841988727858293,0.5454545454545454,0.9371070757670632,1,0.5255759468957438,0.0871328801560648,0.0,0.2848808134689115,0.813697470096327,0.9335252158678514,0.05847130672479715,0.75]"
```

---

## üåê Verf√ºgbare Modelle

| Provider | Model                       | Generierungs-Modell | Evaluierungs-Modell |
|----------|-----------------------------|---------------------|---------------------|
| OpenAI   | gpt-4o                     | ‚úÖ                   | ‚úÖ                   |
| OpenAI   | gpt-4o-mini                | ‚úÖ                   | ‚úÖ                   |
| OpenAI   | o1                         | ‚úÖ                   | ‚úÖ                   |
| OpenAI   | o1-mini                    | ‚úÖ                   | ‚úÖ                   |
| OpenAI   | gpt-3.5-turbo              | ‚úÖ                   | ‚úÖ                   |
| Groq     | gemma2-9b-it               | ‚úÖ                   |                     |
| Groq     | llama-3.3-70b-versatile    | ‚úÖ                   |                     |
| Groq     | llama-3.1-70b-versatile    | ‚úÖ                   |                     |
| Groq     | llama-3.1-8b-instant       | ‚úÖ                   |                     |
| Groq     | llama-guard-3-8b           | ‚úÖ                   |                     |
| Groq     | llama3-70b-8192            | ‚úÖ                   |                     |
| Groq     | llama3-8b-8192             | ‚úÖ                   |                     |
| Groq     | mixtral-8x7b-32768         | ‚úÖ                   |                     |

---

## üéß Hintergrund
Dieses Projekt wurde entwickelt, um die Potenziale von RAG bei der Bewertung von Musikdaten zu erforschen. Durch die Verwendung sowohl von Retrieval- als auch Generationsmetriken liefert es wertvolle Erkenntnisse zur Optimierung von Empfehlungsalgorithmen.

---

Viel Spa√ü bei der Nutzung!