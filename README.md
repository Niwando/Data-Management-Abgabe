# Evaluierung von RAG-Ergebnissen

## ğŸ” ProjektÃ¼bersicht

Dieses Projekt befasst sich mit der Evaluierung von Retrieval-Augmented Generation (RAG) mithilfe verschiedener Evaluierungsmetriken. Dabei kommt insbesondere die Python-Bibliothek [TruLens](https://www.trulens.org) zum Einsatz. Die Evaluierung basiert auf Musikdaten, wobei Nutzer entweder einen vorhandenen Datensatz verwenden oder ihre eigenen Song-Eigenschaften testen kÃ¶nnen.

---

## ğŸ“‚ Ordnerstruktur

Im Root-Verzeichnis befinden sich mehrere zentrale Bereiche: **data** enthÃ¤lt die Rohdaten `raw/`, vorverarbeitete DatensÃ¤tze `preprocessed/` und Ergebnisse `results/`. **evaluation** umfasst Module zur Bewertung, wie Ã„hnlichkeitsmetriken (`similarity/`) und Trulens-Tools (`trulens/`). **setup** bietet Skripte zur Umgebungseinrichtung, wÃ¤hrend **utils** Hilfsfunktionen wie Datenbankverbindungen und Formatierungswerkzeuge bereitstellt. Die Hauptlogik fÃ¼r RAG befindet sich in `rag.py`, und alles ist Ã¼ber die Hauptdatei `run.py` verbunden.

Die Ordnerstruktur ist wie folgt aufgebaut:
```plaintext
.venv/                  
src/                    
â”œâ”€â”€ data/               
â”‚   â”œâ”€â”€ raw/            
â”‚   â”‚   â”œâ”€â”€ data.csv    
â”‚   â”‚   â”œâ”€â”€ dislike.json
â”‚   â”‚   â”œâ”€â”€ good.json
â”‚   â”‚   â”œâ”€â”€ no.py
â”‚   â”‚   â”œâ”€â”€ yes.py
â”‚   â”œâ”€â”€ preprocessed/ 
â”‚   â”‚   â”œâ”€â”€ covariance_matrix.csv
â”‚   â”‚   â”œâ”€â”€ data.csv
â”‚   â”œâ”€â”€ results/ 
â”‚   â”‚   â”œâ”€â”€ overall_results.json     
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ meta_results.py
â”œâ”€â”€ evaluation/         
â”‚   â”œâ”€â”€ similarity/     
â”‚   â”‚   â”œâ”€â”€ cosine.py
â”‚   â”‚   â”œâ”€â”€ euclidean.py
â”‚   â”‚   â”œâ”€â”€ mahalanobis.py
â”‚   â”‚   â”œâ”€â”€ manhattan.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ pearson.py
â”‚   â”‚   â”œâ”€â”€ print_similarity.py
â”‚   â”œâ”€â”€ trulens/        
â”‚       â”œâ”€â”€ evaluation.py
â”œâ”€â”€ setup/              
â”‚   â”œâ”€â”€ create_table.py
â”‚   â”œâ”€â”€ data_to_pgvector.py
â”‚   â”œâ”€â”€ pgvector_extension.py
â”œâ”€â”€ utils/              
â”‚   â”œâ”€â”€ connect_db.py
â”‚   â”œâ”€â”€ formatting.py
â”‚   â”œâ”€â”€ retrieval.py
â”œâ”€â”€ rag.py
.env                               
README.md               
requirements.txt        
run.py                          
```
---

## ğŸ§ Datengrundlage

Die Daten stammen aus dem [Spotify Recommendation Dataset](https://www.kaggle.com/datasets/bricevergnou/spotify-recommendation). Der Datensatz umfasst Informationen wie Danceability, Energy, Tempo und andere musikalische Merkmale.

### Zusammenfassung der Merkmale
- **Danceability**: Eignung eines Songs zum Tanzen.
- **Energy**: Wahrgenommene IntensitÃ¤t und AktivitÃ¤t.
- **Key**: Musikalischer SchlÃ¼ssel.
- **Loudness**: LautstÃ¤rke in Dezibel.
- **Mode**: Modus (Dur oder Moll).
- **Speechiness**: Anteil an gesprochenem Wort.
- **Instrumentalness**: Wahrscheinlichkeit, dass ein Song instrumental ist.
- **Valence**: PositivitÃ¤t der musikalischen Stimmung.

Weitere Informationen zu den Attributen finden Sie in der [Spotify-API-Dokumentation](https://developer.spotify.com/documentation/web-api/).

---

## ğŸ“Š Evaluierungsmetriken

### Retrieval-basierte Metriken
- **Cosine Similarity**: Misst die Ã„hnlichkeit zwischen zwei Vektoren.
- **Euclidean Distance**: AbstandsmaÃŸ in einem n-dimensionalen Raum.
- **Manhattan Distance**: Absolute Distanz zwischen Vektorkoordinaten.
- **Mahalanobis Distance**: Skaliertes AbstandsmaÃŸ.
- **Pearson Correlation**: Korrelation zwischen zwei Variablen.

### Generations-basierte Metriken
- **Correctness**: Korrektheit der generierten Antworten.
- **Groundedness**: Grad, zu dem generierte Antworten durch die Quelle gestÃ¼tzt werden.
- **Relevance**: Relevanz der Antwort (mit BegrÃ¼ndungen).
- **Context Relevance**: Passgenauigkeit der Antwort im Kontext (mit BegrÃ¼ndungen).

---

## ğŸš€ Erste Schritte

### Voraussetzungen
- **Pflicht**: `OPENAI_API_KEY`
- **Optional**: `GROQ_API_KEY` fÃ¼r zusÃ¤tzliche Generierungsmodelle.

### Installation
1. **Virtuelle Umgebung aufsetzen**:
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   ```
2. **AbhÃ¤ngigkeiten installieren**:
   ```bash
   pip install -r requirements.txt
   ```

3. **PostgreSQL und pgVector installieren** (fÃ¼r macOS):
    ```bash
    brew install postgresql@17
    brew install libpq
    echo 'export PATH="/opt/homebrew/opt/libpq/bin:$PATH"' >> ~/.zshrc
    echo 'export LDFLAGS="-L/opt/homebrew/opt/libpq/lib"' >> ~/.zshrc
    echo 'export CPPFLAGS="-I/opt/homebrew/opt/libpq/include"' >> ~/.zshrc
    echo 'export PKG_CONFIG_PATH="/opt/homebrew/opt/libpq/lib/pkgconfig"' >> ~/.zshrc

    source ~/.zshrc
    brew services start postgresql@17
    ```

---

## ğŸ”§ Datenaufbereitung
Die Daten wurden bereits vorverarbeitet. Falls eine erneute Verarbeitung erforderlich ist:
```bash
python src/data_preprocessing.py
```

---

## ğŸ”¢ Setup

1. **.env-Datei einrichten**:
   ```
   DB_NAME=<name>
   DB_USER=<user>
   DB_PASSWORD=<your_password>
   DB_HOST=<your_host>
   DB_PORT=<your_port>
   OPENAI_API_KEY=<your_api_key>
   GROQ_API_KEY=<optional>
   ```

2. **Vektordatenbank vorbereiten**:
   ```bash
   python run.py setup
   ```

---

## ğŸŒ Nutzung

### Evaluierung vorhandener Daten

Evaluieren Sie RAG basierend auf einem vorhandenen Datensatz:
```bash
python run.py eval-data --data-size <DatengrÃ¶ÃŸe> --similarity-search <Methode> --top-k <Anzahl> --model <Generierungsmodell> --eval-model <Evaluierungsmodell>
```
Beispiel:
```bash
python run.py eval-data --data-size 50 --similarity-search cosine --top-k 5 --model "gpt-3.5-turbo" --eval-model "gpt-3.5-turbo"
```

### Interaktive Tests

Erstellen Sie individuelle Anfragen und testen Sie RAG mit benutzerdefinierten Song-Eigenschaften:
```bash
python run.py eval-user --model <Generierungsmodell>
```

---

## ğŸŒ VerfÃ¼gbare Modelle

| Provider | Model                       | Generierungs-Modell | Evaluierungs-Modell |
|----------|-----------------------------|---------------------|---------------------|
| OpenAI   | gpt-4o                     | âœ…                   | âœ…                   |
| OpenAI   | gpt-4o-mini                | âœ…                   | âœ…                   |
| OpenAI   | o1                         | âœ…                   | âœ…                   |
| OpenAI   | o1-mini                    | âœ…                   | âœ…                   |
| OpenAI   | gpt-3.5-turbo              | âœ…                   | âœ…                   |
| Groq     | gemma2-9b-it               | âœ…                   |                     |
| Groq     | llama-3.3-70b-versatile    | âœ…                   |                     |
| Groq     | llama-3.1-70b-versatile    | âœ…                   |                     |
| Groq     | llama-3.1-8b-instant       | âœ…                   |                     |
| Groq     | llama-guard-3-8b           | âœ…                   |                     |
| Groq     | llama3-70b-8192            | âœ…                   |                     |
| Groq     | llama3-8b-8192             | âœ…                   |                     |
| Groq     | mixtral-8x7b-32768         | âœ…                   |                     |

---

## ğŸ§ Hintergrund
Dieses Projekt wurde entwickelt, um die Potenziale von RAG bei der Bewertung von Musikdaten zu erforschen. Durch die Verwendung sowohl von Retrieval- als auch Generationsmetriken liefert es wertvolle Erkenntnisse zur Optimierung von Empfehlungsalgorithmen.

---

Viel SpaÃŸ bei der Nutzung!